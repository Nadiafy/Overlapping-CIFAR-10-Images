{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE7oyG0wv6e0"
      },
      "source": [
        "#Separation of CIFAR-10 Images\n",
        "\n",
        "The model takes as input an image created by averaging two random samples from CIFAR-10 and is tasked with predicting the categories of the two components.\n",
        "\n",
        "The first image belongs to the first five categories (airplane, automobile, bird, cat, deer), while the second belongs to the remaining categories (dog, frog, horse, ship, truck). The model must return two labels, each within a range of five possible values.\n",
        "\n",
        "The evaluation metric for the model is as follows: calculate the classification accuracy for the two component images and then compute their average.\n",
        "\n",
        "The metric should be evaluated on 10,000 inputs generated from test data. Repeat the calculation 10 times and measure the standard deviation, which must be reported.\n",
        "\n",
        "A data generator and some examples are provided below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USdmzjiO0W6D"
      },
      "source": [
        "#Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iHjnh5XP0Sq4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRYiW2ipukZF",
        "outputId": "0d5c8981-51da-4c92-de73-84bcac11aa2c"
      },
      "outputs": [],
      "source": [
        "(cifar10_x_train, cifar10_y_train), (cifar10_x_test, cifar10_y_test) = cifar10.load_data()\n",
        "\n",
        "# Ensures the data has expected dimensions.\n",
        "assert cifar10_x_train.shape == (50000, 32, 32, 3)\n",
        "assert cifar10_x_test.shape == (10000, 32, 32, 3)\n",
        "assert cifar10_y_train.shape == (50000, 1)\n",
        "assert cifar10_y_test.shape == (10000, 1)\n",
        "\n",
        "# Class labels for CIFAR-10 dataset\n",
        "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "# Scales pixel values to [0, 1] for better model performance.\n",
        "cifar10_x_train = (cifar10_x_train/255.).astype(np.float32)\n",
        "cifar10_x_test = (cifar10_x_test/255.).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkiGnU4d0k4d"
      },
      "source": [
        "Let us split the images in two groups, according to their label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Dpey42Vo07Yb"
      },
      "outputs": [],
      "source": [
        "# Separates training data into Group 1 (classes 0-4) and Group 2 (classes 5-9).\n",
        "# Split training data based on class labels (<5 and >=5)\n",
        "cond_1 = cifar10_y_train[:,0] < 5\n",
        "cifar10_x_train_1 = cifar10_x_train[cond_1]\n",
        "cifar10_y_train_1 = cifar10_y_train[cond_1]\n",
        "\n",
        "cond_2 = cifar10_y_train[:,0] >= 5\n",
        "cifar10_x_train_2 = cifar10_x_train[cond_2]\n",
        "cifar10_y_train_2 = cifar10_y_train[cond_2]\n",
        "\n",
        "# Separates testing data into Group 1 (classes 0-4) and Group 2 (classes 5-9).\n",
        "# Split test data based on class labels (<5 and >=5)\n",
        "cond_1_test = cifar10_y_test[:,0] < 5\n",
        "cifar10_x_test_1 = cifar10_x_test[cond_1_test]\n",
        "cifar10_y_test_1 = cifar10_y_test[cond_1_test]\n",
        "\n",
        "cond_2_test = cifar10_y_test[:,0] >= 5\n",
        "cifar10_x_test_2 = cifar10_x_test[cond_2_test]\n",
        "cifar10_y_test_2 = cifar10_y_test[cond_2_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmLYNuR-0s0m"
      },
      "source": [
        "Now we can define the generator. The input consists of two datasets (X1,X2), their corresponding labels (Y1,Y2), and a batch size.\n",
        "\n",
        "The generator returns (x_data,y_data), where:\n",
        "* x_data is a batch of images obtained by averaging random samples from X1 and X2.\n",
        "* y_data is a pair of batches of labels corresponding to the component images, expressed in categorical format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7Y5Zpv5fw2hd"
      },
      "outputs": [],
      "source": [
        "# Data generator function to create mixed batches of samples from two subsets\n",
        "def datagenerator(X1,X2,Y1,Y2,batchsize):\n",
        "  size1 = X1.shape[0]\n",
        "  size2 = X2.shape[0]\n",
        "  Y1_cat = tf.keras.utils.to_categorical(Y1, num_classes=5)\n",
        "  Y2_cat = tf.keras.utils.to_categorical(Y2-5, num_classes=5)\n",
        "  # Convert labels to one-hot encoding\n",
        "  while True:\n",
        "    # Randomly sample indices for both subsets\n",
        "    num1 = np.random.randint(0, size1, batchsize)\n",
        "    num2 = np.random.randint(0, size2, batchsize)\n",
        "    \n",
        "    # Combine samples from both subsets\n",
        "    x_data = (X1[num1] + X2[num2]) / 2.0\n",
        "    y_data = (Y1_cat[num1],Y2_cat[num2])\n",
        "\n",
        "    yield x_data, y_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9lf3TuP2pdQ"
      },
      "source": [
        "\n",
        "Let us instantiate a generator on Cifar10 with batchsize=1, and let's see its behaviour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "29TldJ6-720b"
      },
      "outputs": [],
      "source": [
        "# Tests the generator by visualizing a sample mixed image and its predicted labels.\n",
        "datagen = datagenerator(cifar10_x_train_1,cifar10_x_train_2,cifar10_y_train_1,cifar10_y_train_2,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1DrJVzI3ysV"
      },
      "source": [
        "Let's generate an example, display the image that the model will take as input, and print the categories of the two overlapping components.\n",
        "\n",
        "You can re-run the cell to display new examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "qL1sMtjG8VmG",
        "outputId": "5b9d6599-d407-4e32-dad7-f3f95890f0b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "first: cat, second = dog\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x304d4dff0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Test the generator\n",
        "x, y = next(datagen)\n",
        "\n",
        "print(\"first: {}, second = {}\".format(classes[np.argmax(y[0][0])],classes[np.argmax(y[1][0])+5]))\n",
        "#print(np.min(x[0]),np.max(x[0]))\n",
        "plt.imshow(x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5lzBotwL5QN"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_p4UuG1QF8t"
      },
      "source": [
        "Let us define first of all the test generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQo8_6w-L4WY",
        "outputId": "a626a55c-7df8-456b-adcd-580d4166e184"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# Generate test samples for evaluation\n",
        "testgen = datagenerator(cifar10_x_test_1,cifar10_x_test_2,cifar10_y_test_1,cifar10_y_test_2,10000)\n",
        "eval_samples_x, eval_samples_y = next(testgen)\n",
        "print(eval_samples_x.shape)\n",
        "# Ensure the batch size matches your evaluation needs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MiLnkKROGCD"
      },
      "source": [
        "We now test a model producing random guesses. You will need to replace it with your own predictive model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1GllTEtPN_xv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-11 00:44:02.943570: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
            "2025-01-11 00:44:02.943594: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
            "2025-01-11 00:44:02.943612: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
            "2025-01-11 00:44:02.943823: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2025-01-11 00:44:02.943837: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-11 00:44:03.909647: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 62ms/step - loss: 2.6588 - output_1_accuracy: 0.4220 - output_1_loss: 1.3794 - output_2_accuracy: 0.4826 - output_2_loss: 1.2794 - val_loss: 2.7850 - val_output_1_accuracy: 0.3706 - val_output_1_loss: 1.5251 - val_output_2_accuracy: 0.5245 - val_output_2_loss: 1.2599 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 62ms/step - loss: 2.2247 - output_1_accuracy: 0.5030 - output_1_loss: 1.2143 - output_2_accuracy: 0.6068 - output_2_loss: 1.0105 - val_loss: 3.8082 - val_output_1_accuracy: 0.4682 - val_output_1_loss: 1.3581 - val_output_2_accuracy: 0.3719 - val_output_2_loss: 2.4500 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 62ms/step - loss: 2.0701 - output_1_accuracy: 0.5348 - output_1_loss: 1.1441 - output_2_accuracy: 0.6449 - output_2_loss: 0.9260 - val_loss: 2.0528 - val_output_1_accuracy: 0.5611 - val_output_1_loss: 1.0937 - val_output_2_accuracy: 0.6322 - val_output_2_loss: 0.9591 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 61ms/step - loss: 1.9896 - output_1_accuracy: 0.5593 - output_1_loss: 1.1041 - output_2_accuracy: 0.6618 - output_2_loss: 0.8855 - val_loss: 2.1317 - val_output_1_accuracy: 0.5297 - val_output_1_loss: 1.1978 - val_output_2_accuracy: 0.6327 - val_output_2_loss: 0.9339 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 61ms/step - loss: 1.9131 - output_1_accuracy: 0.5719 - output_1_loss: 1.0658 - output_2_accuracy: 0.6764 - output_2_loss: 0.8473 - val_loss: 2.1685 - val_output_1_accuracy: 0.5085 - val_output_1_loss: 1.1648 - val_output_2_accuracy: 0.6204 - val_output_2_loss: 1.0038 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 61ms/step - loss: 1.8543 - output_1_accuracy: 0.5887 - output_1_loss: 1.0339 - output_2_accuracy: 0.6901 - output_2_loss: 0.8204 - val_loss: 2.5930 - val_output_1_accuracy: 0.5097 - val_output_1_loss: 1.2506 - val_output_2_accuracy: 0.5054 - val_output_2_loss: 1.3424 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 64ms/step - loss: 1.7916 - output_1_accuracy: 0.6016 - output_1_loss: 1.0069 - output_2_accuracy: 0.7066 - output_2_loss: 0.7846 - val_loss: 2.3422 - val_output_1_accuracy: 0.5927 - val_output_1_loss: 1.0098 - val_output_2_accuracy: 0.5135 - val_output_2_loss: 1.3324 - learning_rate: 2.5000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 61ms/step - loss: 1.7285 - output_1_accuracy: 0.6125 - output_1_loss: 0.9830 - output_2_accuracy: 0.7189 - output_2_loss: 0.7456 - val_loss: 1.8233 - val_output_1_accuracy: 0.6030 - val_output_1_loss: 1.0022 - val_output_2_accuracy: 0.6881 - val_output_2_loss: 0.8211 - learning_rate: 2.5000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 62ms/step - loss: 1.7179 - output_1_accuracy: 0.6174 - output_1_loss: 0.9731 - output_2_accuracy: 0.7209 - output_2_loss: 0.7448 - val_loss: 1.8179 - val_output_1_accuracy: 0.6081 - val_output_1_loss: 0.9843 - val_output_2_accuracy: 0.6914 - val_output_2_loss: 0.8336 - learning_rate: 2.5000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 62ms/step - loss: 1.6974 - output_1_accuracy: 0.6186 - output_1_loss: 0.9632 - output_2_accuracy: 0.7263 - output_2_loss: 0.7342 - val_loss: 1.9146 - val_output_1_accuracy: 0.5513 - val_output_1_loss: 1.1428 - val_output_2_accuracy: 0.7213 - val_output_2_loss: 0.7719 - learning_rate: 2.5000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 61ms/step - loss: 1.6851 - output_1_accuracy: 0.6248 - output_1_loss: 0.9573 - output_2_accuracy: 0.7298 - output_2_loss: 0.7278 - val_loss: 2.0195 - val_output_1_accuracy: 0.6279 - val_output_1_loss: 0.9433 - val_output_2_accuracy: 0.6124 - val_output_2_loss: 1.0763 - learning_rate: 2.5000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 61ms/step - loss: 1.6480 - output_1_accuracy: 0.6272 - output_1_loss: 0.9443 - output_2_accuracy: 0.7382 - output_2_loss: 0.7038 - val_loss: 3.1603 - val_output_1_accuracy: 0.5711 - val_output_1_loss: 1.0652 - val_output_2_accuracy: 0.3965 - val_output_2_loss: 2.0951 - learning_rate: 2.5000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 61ms/step - loss: 1.6296 - output_1_accuracy: 0.6342 - output_1_loss: 0.9366 - output_2_accuracy: 0.7423 - output_2_loss: 0.6929 - val_loss: 1.6464 - val_output_1_accuracy: 0.6341 - val_output_1_loss: 0.9360 - val_output_2_accuracy: 0.7365 - val_output_2_loss: 0.7104 - learning_rate: 1.2500e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 61ms/step - loss: 1.5868 - output_1_accuracy: 0.6423 - output_1_loss: 0.9129 - output_2_accuracy: 0.7505 - output_2_loss: 0.6739 - val_loss: 1.6172 - val_output_1_accuracy: 0.6235 - val_output_1_loss: 0.9334 - val_output_2_accuracy: 0.7469 - val_output_2_loss: 0.6838 - learning_rate: 1.2500e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 61ms/step - loss: 1.5767 - output_1_accuracy: 0.6429 - output_1_loss: 0.9118 - output_2_accuracy: 0.7546 - output_2_loss: 0.6649 - val_loss: 1.6544 - val_output_1_accuracy: 0.6325 - val_output_1_loss: 0.9385 - val_output_2_accuracy: 0.7296 - val_output_2_loss: 0.7160 - learning_rate: 1.2500e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 61ms/step - loss: 1.5813 - output_1_accuracy: 0.6494 - output_1_loss: 0.9045 - output_2_accuracy: 0.7501 - output_2_loss: 0.6769 - val_loss: 1.6260 - val_output_1_accuracy: 0.6428 - val_output_1_loss: 0.9014 - val_output_2_accuracy: 0.7215 - val_output_2_loss: 0.7246 - learning_rate: 1.2500e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 61ms/step - loss: 1.5578 - output_1_accuracy: 0.6546 - output_1_loss: 0.8929 - output_2_accuracy: 0.7521 - output_2_loss: 0.6649 - val_loss: 1.6601 - val_output_1_accuracy: 0.6503 - val_output_1_loss: 0.8994 - val_output_2_accuracy: 0.7154 - val_output_2_loss: 0.7607 - learning_rate: 1.2500e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 62ms/step - loss: 1.5541 - output_1_accuracy: 0.6539 - output_1_loss: 0.8919 - output_2_accuracy: 0.7558 - output_2_loss: 0.6622 - val_loss: 1.5124 - val_output_1_accuracy: 0.6622 - val_output_1_loss: 0.8655 - val_output_2_accuracy: 0.7629 - val_output_2_loss: 0.6468 - learning_rate: 6.2500e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 62ms/step - loss: 1.5336 - output_1_accuracy: 0.6596 - output_1_loss: 0.8770 - output_2_accuracy: 0.7557 - output_2_loss: 0.6565 - val_loss: 1.5648 - val_output_1_accuracy: 0.6462 - val_output_1_loss: 0.9053 - val_output_2_accuracy: 0.7547 - val_output_2_loss: 0.6595 - learning_rate: 6.2500e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 62ms/step - loss: 1.5350 - output_1_accuracy: 0.6564 - output_1_loss: 0.8860 - output_2_accuracy: 0.7579 - output_2_loss: 0.6490 - val_loss: 1.5451 - val_output_1_accuracy: 0.6517 - val_output_1_loss: 0.8878 - val_output_2_accuracy: 0.7589 - val_output_2_loss: 0.6573 - learning_rate: 6.2500e-05\n"
          ]
        }
      ],
      "source": [
        "# Define the predictive model\n",
        "def predictive_model():\n",
        "    # Input layer\n",
        "    input_layer = layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "    # Shared Convolutional Layers\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Dropout for regularization\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # First output (classes 0-4)\n",
        "    output_1 = layers.Dense(5, activation='softmax', name='output_1')(x)\n",
        "\n",
        "    # Second output (classes 5-9)\n",
        "    output_2 = layers.Dense(5, activation='softmax', name='output_2')(x)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=input_layer, outputs=[output_1, output_2])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "                  loss={'output_1': 'categorical_crossentropy', 'output_2': 'categorical_crossentropy'},\n",
        "                  metrics={'output_1': 'accuracy', 'output_2': 'accuracy'})\n",
        "    return model\n",
        "\n",
        "# Instantiate the model\n",
        "model = predictive_model()\n",
        "\n",
        "# Train the model using the generator\n",
        "batch_size = 64\n",
        "steps_per_epoch = 50000 // batch_size\n",
        "validation_steps = 10000 // batch_size\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Learning rate scheduler to adjust learning rate dynamically\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "\n",
        "history = model.fit(\n",
        "    datagenerator(cifar10_x_train_1, cifar10_x_train_2, cifar10_y_train_1, cifar10_y_train_2, batch_size),\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=20,\n",
        "    validation_data=datagenerator(cifar10_x_test_1, cifar10_x_test_2, cifar10_y_test_1, cifar10_y_test_2, batch_size),\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[early_stopping, lr_scheduler]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gomFTuuDOy8A"
      },
      "outputs": [],
      "source": [
        "# Modify ------------Refactor if additional metrics are needed--------------\n",
        "\n",
        "# Evaluation function for models\n",
        "def eval_model(model):\n",
        "    eval_samples_x, eval_samples_y = next(testgen)\n",
        "    predictions = model.predict(eval_samples_x)\n",
        "    # Extract predictions for both outputs\n",
        "    pred_output_1 = np.argmax(predictions[0], axis=1)\n",
        "    pred_output_2 = np.argmax(predictions[1], axis=1)\n",
        "    \n",
        "    # Calculate accuracy for both outputs\n",
        "    correct_guesses_1 = pred_output_1 == np.argmax(eval_samples_y[0], axis=1)\n",
        "    correct_guesses_2 = pred_output_2 == np.argmax(eval_samples_y[1], axis=1)\n",
        "\n",
        "    return (np.mean(correct_guesses_1) + np.mean(correct_guesses_2)) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4AL2M6yjJno",
        "outputId": "d84ecfb8-299f-4e37-85ee-c69b83a39e0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "Average accuracy: 0.7081999999999999\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------------------------------------\n",
        "average_accuracy = eval_model(model)\n",
        "print(f\"Average accuracy: {average_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7usBI88dje70"
      },
      "source": [
        "As expected, the accuracy is around 1/5 = 0.2\n",
        "\n",
        "Let us repeat the evaluation ten times, and compute the standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFu8iEt9jdZA",
        "outputId": "93fa99f4-972a-4795-917b-b1db97dc7ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "mean accuracy =  0.7095550000000002\n",
            "standard deviation =  0.004168539912247464\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the random model\n",
        "repeat_eval = 10\n",
        "eval_results = []\n",
        "for i in range(repeat_eval):\n",
        "  eval_results.append(eval_model(model))\n",
        "print(\"mean accuracy = \", np.mean(eval_results))\n",
        "print(\"standard deviation = \", np.std(eval_results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save_weights('cifar10_model.weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1yTRAzn4i9g"
      },
      "source": [
        "# What to Submit\n",
        "\n",
        "As usual, you need to submit a single notebook that must be executable on Colab. The notebook should be properly commented and include a complete record of the training process, as well as the calculation of accuracy according to the guidelines provided above.\n",
        "\n",
        "# Good luck!\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3.10.3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
